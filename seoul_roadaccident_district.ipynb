{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matplotlib practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세팅 불러오기\n",
    "st.set_page_config(\n",
    "    page_title=\"서울시 교통사고 현황\",\n",
    "    page_icon=\"Cars\",\n",
    "    #layout=\"wide\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 16:43:28.511 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\KRX\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator(_root_container=0, _provided_cursor=None, _parent=None, _block_type=None, _form_data=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.markdown('<style>div.appview-container{background-color: #f7f6f4;}</style>',unsafe_allow_html=True)\n",
    "st.markdown('<style>div[data-testid=\"stForm\"]{background-color: #fcfbfb;}</style>',unsafe_allow_html=True)\n",
    "st.markdown('<style>section[data-testid=\"stSidebar\"]{background-color: #dfdedd;}</style>',unsafe_allow_html=True)\n",
    "\n",
    "st.title(\"서울시 구별 교통사고 현황\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalHashError",
     "evalue": "module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load_data()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load_data at 0x00000278815FAEE0>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:626\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    627\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 402\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:714\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalHashError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/ArubaKLM/Viz-Practice/main/road_accident_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m----> 8\u001b[0m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:627\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_spinner:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m spinner(message):\n\u001b[1;32m--> 627\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_or_create_cached_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_or_create_cached_value()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:552\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func.<locals>.get_or_create_cached_value\u001b[1;34m()\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_key\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;66;03m# Delay generating the cache key until the first call.\u001b[39;00m\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;66;03m# This way we can see values of globals, including functions\u001b[39;00m\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;66;03m# defined after this one.\u001b[39;00m\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;66;03m# If we generated the key earlier we would only hash those\u001b[39;00m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;66;03m# globals by name, and miss changes in their code or value.\u001b[39;00m\n\u001b[1;32m--> 552\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m \u001b[43m_hash_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_optional_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# First, get the cache that's attached to this function.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# This cache's key is generated (above) from the function's code.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m mem_cache \u001b[38;5;241m=\u001b[39m _mem_caches\u001b[38;5;241m.\u001b[39mget_cache(cache_key, max_entries, ttl)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:679\u001b[0m, in \u001b[0;36m_hash_func\u001b[1;34m(func, hash_funcs)\u001b[0m\n\u001b[0;32m    668\u001b[0m update_hash(\n\u001b[0;32m    669\u001b[0m     (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m),\n\u001b[0;32m    670\u001b[0m     hasher\u001b[38;5;241m=\u001b[39mfunc_hasher,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    673\u001b[0m     hash_source\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    674\u001b[0m )\n\u001b[0;32m    676\u001b[0m \u001b[38;5;66;03m# Include the function's body in the hash. We *do* pass hash_funcs here,\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;66;03m# because this step will be hashing any objects referenced in the function\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;66;03m# body.\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m \u001b[43mupdate_hash\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhasher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_hasher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhash_funcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_reason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHashReason\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCACHING_FUNC_BODY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m func_hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[0;32m    687\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem_cache key for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, cache_key\n\u001b[0;32m    689\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:108\u001b[0m, in \u001b[0;36mupdate_hash\u001b[1;34m(val, hasher, hash_reason, hash_source, context, hash_funcs)\u001b[0m\n\u001b[0;32m    105\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mhash_source \u001b[38;5;241m=\u001b[39m hash_source\n\u001b[0;32m    107\u001b[0m ch \u001b[38;5;241m=\u001b[39m _CodeHasher(hash_funcs)\n\u001b[1;32m--> 108\u001b[0m \u001b[43mch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:385\u001b[0m, in \u001b[0;36m_CodeHasher.update\u001b[1;34m(self, hasher, obj, context)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, hasher, obj: Any, context: Optional[Context] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(b)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:374\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalHashError(ex, obj)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# In case an UnhashableTypeError (or other) error is thrown, clean up the\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# stack so we don't get false positives in future hashing calls\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    356\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpush(obj)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(b)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:626\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    624\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    627\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n\u001b[0;32m    628\u001b[0m     defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_is_blacklisted:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 402\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:714\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[1;31mInternalHashError\u001b[0m: module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load_data()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load_data at 0x00000278815FAEE0>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            "
     ]
    }
   ],
   "source": [
    "# ========== DATA & SETUP\n",
    "# Load data\n",
    "@st.cache\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/ArubaKLM/Viz-Practice/main/road_accident_data.csv\")\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SIDEBAR\n",
    "# Customise map\n",
    "st.sidebar.subheader(\"커스텀 디자인 만들기\")\n",
    "\n",
    "with st.form(key = 'Form1'):\n",
    "    with st.sidebar:\n",
    "        main_title = st.text_input(\"제목\", \"서울시 구별 교통사고 현황\")\n",
    "        title_fontsize = st.number_input(\"제목 크기\", min_value=10, max_value=40, value=30)\n",
    "        clr_title = st.color_picker('제목 색상', '#184e77')\n",
    "        clr_background = st.color_picker('배경 색상', '#f7f6f4')\n",
    "        clr_value = st.color_picker('수치 색상', '#1D4D79')\n",
    "        clr_line = st.color_picker('선 색상', '#EC0808')\n",
    "        clr_area = st.color_picker('영역 색상', '#F16322')\n",
    "        alpha_area = st.number_input(\"투명도: 0(투명) ~ 1(불투명)\",min_value=0.00, max_value=1.00, value=0.5)\n",
    "        submitted = st.form_submit_button('적용하기')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== FILTER SELECTIONS\n",
    "\n",
    "row_0, row_01 = st.columns([1,2])\n",
    "\n",
    "with st.form(key='columns_in_form'):\n",
    "    st.markdown('데이터 탐색하기')\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        Harm = st.radio(\"사고 피해\",('사고건수', '부상자수', '사망자수'))\n",
    "    with col2:\n",
    "        Category = st.radio(\"사고 유형\", ('총계', '차-사람', '차-차', '차량단독'))\n",
    "    submitted = st.form_submit_button('적용하기')\n",
    "    # 기간 추가해서 조정할 수 있도록 해보자\n",
    "\n",
    "footer = \"원데이터: https://data.seoul.go.kr/dataList/322/S/2/datasetView.do \\n 제작: 윤준식 | Lisa Hornung의 https://github.com/liloho/london-cycling-rates 프로젝트를 참고하여 제작함\"\n",
    "subtitle = \"2007~2021년 서울시 자치구별\" + Harm.lower() + Category.lower() # ex 차대차 사망건수\n",
    "\n",
    "st.write(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "display_dict = {\"seoul\":\"서울시\", \"jong\":\"종로\", \"jungg\":\"중구\", \"yong\":\"용산\", \n",
    "                \"sungd\":\"성동\", \"gwang\":\"광진\", \"dongd\":\"동대문\", \"jungr\":\"중랑\", \n",
    "                \"sungb\":\"성북\", \"gangb\":\"강북\", \"dob\":\"도봉\", \"now\":\"노원\", \n",
    "                \"eun\":\"은평\", \"seod\":\"서대문\", \"ma\":\"마포\", \n",
    "                \"yang\":\"양천\", \"gangs\":\"강서\", \"gur\":\"구로\", \"gum\":\"금천\", \n",
    "                \"yeong\":\"영등포\", \"dongj\":\"동작\", \"gwan\":\"관악\", \n",
    "                \"seo\":\"서초\", \"gangn\":\"강남\", \"song\":\"송파\", \"gangd\":\"강동\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== VISUALISATION\n",
    "\n",
    "# Map view\n",
    "\n",
    "## Plotting\n",
    "#filter data set based on input\n",
    "\n",
    "data = df[(df[\"district\"].isin(display_dict.keys())) & (df[\"harm\"]==Harm) & (df[\"category\"]==Category)]\n",
    "data[\"Display Name\"] = data[\"district\"].map(display_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========= Layout\n",
    "# Initialise Figure and define layout\n",
    "#8,7 | 10, 8.75\n",
    "layout = [\n",
    "        [\"___\",\"___\",\"___\",\"___\",\"도봉\",\"___\",\"___\",\"___\"],\n",
    "        [\"___\",\"___\",\"은평\",\"___\",\"강북\",\"노원\",\"___\",\"___\"],\n",
    "        [\"___\",\"___\",\"서대문\",\"종로\",\"성북\",\"동대문\",\"중랑\",\"___\"],\n",
    "        [\"___\",\"___\",\"마포\",\"중구\",\"성동\",\"광진\",\"___\",\"___\"],\n",
    "        [\"___\",\"___\",\"___\",\"용산\",\"___\",\"___\",\"___\",\"___\"],\n",
    "        [\"강서\",\"양천\",\"영등포\",\"___\",\"서초\",\"강남\",\"송파\",\"강동\"],\n",
    "        [\"___\",\"구로\",\"금천\",\"동작\",\"___\",\"___\",\"___\",\"___\"],\n",
    "        [\"___\",\"___\",\"___\",\"관악\",\"___\",\"___\",\"___\",\"___\"],\n",
    "        ]\n",
    "fig,axs = plt.subplot_mosaic(layout, figsize=(12,9), empty_sentinel=\"___\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig.set_facecolor(clr_background)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1, left=0.05, right=0.95, bottom=0.05, top=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#=========== Plotting\n",
    "# 자치구 표시하기\n",
    "y_values = ['2007', '2008', '2009','2010' ,'2011',\n",
    "            '2012', '2013', '2014', '2015', '2016',\n",
    "            '2017', '2018', '2019', '2020', '2021']        \n",
    "x_values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "height = max(data[y_values].max()) + 20\n",
    "\n",
    "## Loop through all boroughs and map their values\n",
    "for ax in axs:\n",
    "    data_filtered = data[data[\"자치구\"]==ax]\n",
    "        \n",
    "    #구의 이름 나타내기\n",
    "    axs[ax].text(1.05, height-10, ax, fontsize=20, ha=\"left\", va='top', color=\"#111111\")\n",
    "    \n",
    "    #영역 나타내기\n",
    "    axs[ax].fill_between(x_values, list(data_filtered[y_values].values[0]), zorder=1, color=clr_area, alpha=0.7,\n",
    "                    linewidth=0)   \n",
    "    axs[ax].plot(x_values, list(data_filtered[y_values].values[0]), zorder=2, \n",
    "             color=clr_line,linewidth=2.5)    \n",
    "    \n",
    "    #마지막 연도 점 나타내기\n",
    "    axs[ax].scatter(max(x_values), list(data_filtered[y_values].values[0])[-1], zorder=3,color=clr_line)\n",
    "    \n",
    "    #최신 연도의 수치 나타내기\n",
    "    axs[ax].text(max(x_values)-0.05, height-7, '{:<10d}'.format(list(data_filtered[y_values].values[0])[-1]), \n",
    "             ha=\"right\", fontsize=20, fontweight='bold', va='top', color=clr_value)\n",
    "    \n",
    "    #배경 색 설정\n",
    "    axs[ax].set_xlim(xmin=0.8, xmax=15.2)\n",
    "    axs[ax].set_ylim(ymax=height, ymin=0) \n",
    "    axs[ax].set_facecolor(clr_background)    \n",
    "    axs[ax].axis(\"off\")\n",
    "\n",
    "#============= 범례           \n",
    "#add legend\n",
    "lgd = fig.add_axes([0.8, 0.05, 0.1, 0.1]) #axes to hold legend\n",
    "lgd.text(1.05,height-3,data[\"자치구\"][0], fontsize=8, ha=\"left\", va='top', color=\"#111111\")\n",
    "lgd.fill_between(x_values,list(data.loc[0][y_values].values), zorder=1,color=\"#999999\", alpha=0.7,linewidth=0)    \n",
    "lgd.plot(x_values,list(data.loc[0][y_values].values), zorder=2,color=\"#333333\",linewidth=1.5)    \n",
    "lgd.scatter(max(x_values),list(data.loc[0][y_values].values)[-1], zorder=3,color=\"#333333\")\n",
    "lgd.text(max(x_values)-0.05, height-2, '{:,.0f}%'.format(list(data.loc[0][y_values].values)[-1]), \n",
    "        ha=\"right\", fontsize=15, fontweight='bold', va='top', color=\"#333333\")\n",
    "lgd.set_xlim(xmin=0.8, xmax=6.2)\n",
    "lgd.set_ylim(ymax=height, ymin=0) \n",
    "lgd.set_facecolor(\"#E4E4E4\")\n",
    "for pos in [\"top\", \"bottom\", \"right\", \"left\"]:\n",
    "    lgd.spines[pos].set_visible(False)\n",
    "lgd.set_xticks([1,6], [\"2007\", \"2021\"],fontsize = 10)\n",
    "lgd.set_yticks([])\n",
    "lgd.annotate('2021년\\n수치', xy=(max(x_values)+0.3, height-10), xycoords='data', xytext=(10, 0), textcoords='offset points', \n",
    "                   fontsize=11, ha='left', va='center', annotation_clip=False,\n",
    "                    arrowprops=dict(arrowstyle=\"->\",facecolor='black'))\n",
    "lgd.annotate('자치구', xy=(min(x_values)+0.2, height-1), xycoords='data', xytext=(0, 16), textcoords='offset points', \n",
    "                   fontsize=11, ha='center', va='center', annotation_clip=False,\n",
    "                    arrowprops=dict(arrowstyle=\"->\",facecolor='black'))\n",
    "\n",
    "\n",
    "\n",
    "#=============== Text           \n",
    "## Add titles and footer\n",
    "y_pos = 1.05\n",
    "x_pos = 0.05\n",
    "\n",
    "fig.text(x_pos, y_pos, main_title, fontsize=title_fontsize, ha='left',va=\"top\",\n",
    "             fontweight=\"bold\",  color=clr_title)\n",
    "fig.text(x_pos, y_pos-(title_fontsize*0.2*0.01), subtitle, fontsize=15, ha='left',va=\"top\",\n",
    "             fontweight=\"normal\",   color=\"#111111\")\n",
    "fig.text(x_pos, -0.05, footer, fontsize=11, ha='left',va=\"center\",\n",
    "             fontweight=\"normal\",  linespacing=1.5, color=\"#111111\")\n",
    "\n",
    "\n",
    "#============ 서울시 전체\n",
    "#inner = df[(df[\"Area name\"]==\"Inner London\") & (df[\"Frequency\"]==frequency) & (df[\"Purpose\"]==purpose)][\"2021\"].iloc[0]\n",
    "#outer = df[(df[\"Area name\"]==\"Outer London\") & (df[\"Frequency\"]==frequency) & (df[\"Purpose\"]==purpose)][\"2021\"].iloc[0]\n",
    "#강동\n",
    "#강북\n",
    "#서북\n",
    "#도심\n",
    "서울시 = df[(df[\"자치구\"]==\"서울특별시\") & (df[\"사고유형\"]==Category) & (df[\"사고유형\"]==Harm)][\"2021\"].iloc[0]\n",
    "\n",
    "fig.text(x_pos, y_pos-0.14,  \"2021년 전체: \" + ''.format(서울시), fontsize=15, ha='left',va=\"top\",\n",
    "         fontweight=\"bold\",color=clr_value)\n",
    "fig.text(x_pos, y_pos-0.18, \"Inner: \" + '{:,.0f}%'.format(inner) + \"  |  Outer: \" + '{:,.0f}%'.format(outer) , \n",
    "         fontsize=11, ha='left',va=\"top\", fontweight=\"regular\",color=\"#111111\")\n",
    "\n",
    "st.pyplot(fig)\n",
    "\n",
    "\n",
    "## ======= Download\n",
    "st.write(\"\")\n",
    "st.write(\"\")\n",
    "\n",
    "# download data\n",
    "csv = data[['ONS Code', 'Area name','2016', '2017', '2018','2019', '2020', '2021']].to_csv(index=False)\n",
    "#목록 열거\n",
    "\n",
    "st.download_button(\n",
    "    label=\"CSV로 데이터 내려받기\",\n",
    "    data=csv,\n",
    "    file_name='seoul_car_accident_%s_%s.csv' % (Harm.lower(), Category.lower()),\n",
    "    mime='text/csv',\n",
    ")\n",
    "\n",
    "#download image\n",
    "plt.savefig(\"seoul_car_accident.png\",bbox_inches=\"tight\", pad_inches=0.2)\n",
    "with open(\"london_cycling_rates.png\", \"rb\") as file:\n",
    "    btn = st.download_button(\n",
    "            label=\"이미지 저장하기\",\n",
    "            data=file,\n",
    "            file_name=\"london_cycling_rates.png\",\n",
    "            mime=\"image/png\"\n",
    "          )\n",
    "\n",
    "st.write(\"\")\n",
    "st.subheader(\"About\")\n",
    "st.markdown(\"Data source: [Active Lives Survey 2021](https://www.gov.uk/government/statistics/walking-and-cycling-statistics-england-2021)\")\n",
    "st.markdown(\"App created by Lisa Hornung. Visit my [website](https://inside-numbers.com/) or follow me on [Github](https://github.com/Lisa-Ho), [Mastodon](https://fosstodon.org/@LisaHornung), [Twitter](https://twitter.com/LisaHornung_).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(0, 0.2, 0.4, 0.6, 0.8, 1) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.arange(0,10,0.01)\n",
    "fit = plt.figure()\n",
    "plt.plot(x, np.sin(x))\n",
    "plt.plot(x, np.cos(x))\n",
    "plt.plot(np.random.randn(50).cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.random.randn(50).cumsum(), linestyle='-')\n",
    "plt.plot(np.random.randn(50).cumsum(), linestyle='dashed')\n",
    "plt.plot(np.random.randn(50).cumsum(), linestyle='dashdot')\n",
    "plt.plot(np.random.randn(50).cumsum(), linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "플롯 축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.random.randn(50).cumsum(), linestyle='dotted')\n",
    "plt.xlim(-1,50)\n",
    "plt.ylim(-1,50)\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.random.randn(50), label='A')\n",
    "plt.plot(np.random.randn(50), label='B')\n",
    "plt.axis('equal')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"randon.randm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font1 = { 'family': 'DejaVu Sans', 'size' : '24', 'color' : 'darkblue'}\n",
    "font2 = { 'family': 'Liberation Mono', 'size' : '24', 'weight': 'bold', 'color' : 'black'}\n",
    "font3 = { 'family': 'STIXGeneral', 'size': 16, 'weight' : 'light'}\n",
    "\n",
    "plt.plot([1,2,4], [1,2,6])\n",
    "plt.title('title', fontdict=font1)\n",
    "plt.xlabel('x', fontdict=font2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.random.randn(10), '-r', label='A')\n",
    "ax.plot(np.random.randn(10), '--b', label='B')\n",
    "ax.legend(loc= 'upper center', frameon = False, ncol=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.legend(loc= 'upper center', fancybox= True, framealpha= .3, ncol=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 1000)\n",
    "y = np.cos(x[:, np.newaxis] * np.arange(0, 2, 0.2))\n",
    "lines = plt.plot(x, y)\n",
    "plt.legend(lines[:3], ['c1', 'c2', 'c3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([f.name for f in mpl.font_manager.fontManager.ttflist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x , y[:,0], label = 'c1')\n",
    "plt.plot(x , y[:,1], label = 'c2')\n",
    "plt.plot(x , y[:,2], label = 'c3')\n",
    "plt.plot(x , y[:,3:], label = 'c4')\n",
    "plt.legend(framealpha=1, frameon= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.linspace(0,20,100)\n",
    "I = np.cos(x) - np.cos(x[:, np.newaxis])\n",
    "\n",
    "plt.imshow(I, cmap='RdBu')\n",
    "plt.colorbar();\n",
    "plt.clim(-1,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I, cmap=plt.cm.get_cmap('Blues', 5))\n",
    "plt.colorbar();\n",
    "plt.clim(-1,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axes()\n",
    "plt.axes([0.5,0.5,0.1,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,10):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.text(0.5,0.5, str((3,3,i)), na='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3, sharex='col', sharey= 'row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = plt.GridSpec(2,3, wspace=0.4, hspace=0.4)\n",
    "\n",
    "plt.subplot(grid[0,0])\n",
    "plt.subplot(grid[0,1:])\n",
    "plt.subplot(grid[1,:2])\n",
    "plt.subplot(grid[1,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,6))\n",
    "\n",
    "x=range(1,21);\n",
    "columns = [np.random.randn(20) * i for i in range(1, 7)]\n",
    "\n",
    "i = 0\n",
    "for c in columns:\n",
    "    i +=1\n",
    "    \n",
    "    plt.subplot(3,2,i)\n",
    "    plt.plot(x, c, marker='o', linewidth=1, label=c)\n",
    "    plt.xlim(-1,21)\n",
    "    plt.ylim(c.min()-1, c.max()+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3ad04790ffc83384e6487486f84667367a49b70d70ec3839dc413a7a4daa548"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
